<d-article>
%% contents.html
<p>Growing Neural Cellular Automata <d-cite key="mordvintsev2020growing"></d-cite> demonstrated how simple cellular automata (CAs) can learn to self-organise into complex shapes while being resistant to perturbations. Such a  computational model approximates a solution to an open question in biology - namely - how do cells cooperate to create a complex multicellular anatomy and work to regenerate it upon damage?  The model parameterizing the cells’ rules is parameter-efficient and end-to-end differentiable, illustrating a new approach to the modeling of the regulation of anatomical homeostasis. In this work we show how a CA can be instead repurposed for a common task in machine learning - classification. We pose the question: can CAs, with cells arranged in the shape of a certain digit,<strong> </strong><i>come to total agreement regarding what digit they compose?</i> This is closely related to another unsolved problem in cell and developmental biology: anatomical surveillance and the ability to decide whether a pattern is correct or whether cells need to remodel the current anatomy. For example, a salamander tail surgically transplanted to the flank slowly remodels to a limb - the organ that belongs at this location <d-cite key="farinella-ferruzza_1956"></d-cite>. Similarly, a tadpole with craniofacial organs in the wrong positions become normal frogs because they remodel their face to place the eye, mouth, nostrils, etc. in their correct locations <d-cite key="vandenberg_adams_levin_2012"></d-cite>. All of these examples illustrate the ability of biological systems to determine their current anatomical structure and decide whether it matches a species-specific target morphology <d-cite key="pezzulo_levin_2016"></d-cite>. Despite the recent progress in molecular biology of genes required for this process, it is now essential to develop a computational understanding of candidate algorithms sufficient for cell collectives to measure and classify their own large-scale morphology. More broadly, it is important to create computational models of swarm intelligence that make explicit and distinguish the dynamics of basal cognition<d-cite key="Baluska_Levin_2016"></d-cite><d-cite key="Lyon_2006"></d-cite> of single cells vs. cell collectives. What our work specifically shows is that there are things that can be taught to a collective of cells which would be impossible for them to learn individually (by training or engineering a single cell). Cells’ being trained in unison (while communicating with each other) allows them to learn more complex behaviour than any attempt to train them one by one, which has important implications for strategies in regenerative medicine that focus on cellular re-wiring vs. communication with cellular collectives <d-cite key="Mathews_Levin_2018"></d-cite><d-cite key="Pezzulo_Levin_2015"></d-cite>.</p>

<p>Suppose there are agents arranged in a grid. They do not know what position of the grid they occupy, nor can they see or communicate any further than their immediate neighbors. They can also observe whether a neighbor is missing. Now suppose that these agents are arranged to form a large digit, as seen from directly above. Given that all the agents operate under the same rules, can they form a communication protocol such that after a number of iterations of communication <i>all of the agents know which digit they are forming?</i></p>
<p>Furthermore, if some agents were to be removed and added to form a new digit from a preexisting one, would they be able to know which the new digit is?</p>
<p>Because digits are not rotationally invariant (i.e. 6 is a rotation of 9), we presume the agents must be made aware of their orientation with respect to the grid. Therefore, while they do not know where they are, they know where up, down, left and right are. This corresponds to biological situations where the remodeling structures exist in the context of a larger body and a set of morphogen gradients or tissue polarity that indicate directional information with respect to the three major body axes.</p>

<p>We introduce a self-classifying MNIST model.</p>

<p><figure style="margin-left:auto; margin-right: auto; grid-column:page; width:100%; max-width:500px;">
  <object data="figures/mnist_digits.png" type="image/png" style="width:100%"></object>
<figcaption style="">
A visualisation of a random sample of digits from MNIST, each shaded by the colour corresponding its label.
</figcaption>
</figure></p>

<p>Each sample of the MNIST dataset <d-cite key="lecun_mnist"></d-cite> consists of a 28x28 image with a single monochrome channel - classically displayed in greyscale. The label is an integer in $[0,9]$.</p>

<p>Our goal is for all cells residing inside the bounds, or on the contour, of a digit to correctly output the label of the digit. To convey this structural information to the cells we make a distinction between alive and dead cells, by rescaling the values of the image to [0, 1] and treating a cell as alive if and only if it’s value in the MNIST sample is $> 0.1$. This can be thought roughly as equivalent to placing living cells or beings in a mould - a cookie-cutter perhaps - and having them identify the shape formed by the cookie-cutter. We visualize the label output by each cell with a colour - as can be seen above. The mapping of label to colour is used in all figures throughout this article. Please note there is a slider in the interactive demo controls to adjust the color palette in order to aid readers who may find it difficult to distinguish the labels with the original palette. </p>
<h2 id='model'>Model</h2>

<p>The model used in this article is a variant of the one used in Growing Cellular Automata <d-cite key="mordvintsev2020growing"></d-cite>. For readers unfamiliar with its implementation, we refer to its model section.</p>

<p>The differences with regards to the Growing CA model are detailed below.</p>
<h3>Target labels</h3>
<p>The work in Growing CA used a label, or ground truth, in the form of an RGB image, with the loss encouraging the first three state channels of the cells to approximate this image. For our experiments, we treat the last ten channels of our cells as a pseudo-distribution over each possible label (digit). During inference, we simply pick the label corresponding to the channel with the highest output value.</p>
<h3>“Alive”-ness and cell states</h3>
<p>In “Growing CA” we decided the concept of a cell being “alive” or “dead” to be a function of its own alpha channel, as well as its neighbours, in a manner not too dissimilar to the original Game of Life rules. Recall that “alive” cells are cells which update their state, while dead cells are “frozen” and do not undergo updates. In contrast to biological life what we call “dead” cells aren’t “dead” in the sense of being non-existent or decayed, but rather “frozen” - they are visible to other cells and maintain their state throughout the system’s evolution. For our experiments, the spatial distribution of alive and dead cells is explicitly encoded in the input data values, and we perform computations for alive cells only, whose respective values in MNIST are $> 0.1$. It is important to note that the values from MNIST are exposed to the cell update rule as an immutable channel of cell state - i.e. cells are made aware of their own value in the corresponding MNIST sample as well as that of their neighbourhood cells. Therefore, given 19 mutable cell state channels (nine general purpose state channels for communication, 10 output state channels for digit classification) and an immutable “MNIST channel”, each cell perceives 19 + one state channel from the neighborhood, but outputs state updates for only the 19 mutable state channels.</p>

<p>Keen readers may also notice that such a constraint will require digits to consist of a single fully connected component in order for classification to be possible, as any disconnected components will be unable to propagate information between themselves. However, this design decision was made in the context of staying true to an analogy of having biological cells or robot swarms placed in a distinct shape, and having them identify the shape they are in.</p>

<p>The vast majority of samples from MNIST are fully connected, but some aren’t. We do not expect our models to classify non-connected minor components correctly, but we do not remove them.</p>
<h3>Perception</h3>
<p>Growing CA made use of a fixed three-by-three convolution to estimate the gradient of state in x and y (using Sobel filters). We found that fully trainable three-by-three kernels outperform their fixed counterpart, and use trainable kernels in this work.</p>

<p>Overall, the model remains small by standards of contemporary deep learning (<25k parameters). In this work, we are interested in demonstrating a novel approach to classification and do not attempt to maximise the validation accuracy of the model by increasing the number of parameters or any other tuning, although we suspect that just as with most models based off of deep neural networks one would observe a positive correlation between accuracy and model size.</p>
<h2 id='experiment-1'>Experiment 1: Self-classify, persist and mutate</h2>
<p>This first experiment makes use of the same training paradigm as discussed in Growing CA. Training is done with a pool of initial samples, to allow the model to learn to persist, and the converged states are perturbed. The perturbation performed in this work is, however, markedly different. In experiment three of the Growing CA article, states of cells were at random destroyed in an attempt to make the CAs resistant to destructive perturbations (analogous to traumatic tissue loss). In this work, our goal is of a broader scope: while having regenerative properties is favourable, we also want our CAs to <i>be capable of correcting themselves </i><i>when the underlying digits change</i> (corresponding to a teratogenic influence during development or the case of an incorrect or incomplete remodeling event such as metamorphosis or rescaling). The distinction between training them from scratch and having them learn to accommodate for perturbations is subtle but important. An important feature of life is to react to changing environmental conditions or changes external to oneself. If our virtual cells simply learned to recognize a digit, then entered some dormant state and did not react to any further changes we would be missing this key property of living organisms. One could imagine a trivial solution in the absence of perturbations, where a single “wave” of information is passed from the boundaries of the digit inwards, then back out, allowing all cells to agree on the correct classification, then no further communication between cells. By introducing perturbations to new digits, the cells have to be in constant communication and achieve a “dynamic” homeostasis - continually “kept on their toes” for any new or further communication from their neighbours.</p>

<p>In order to build robustness to perturbation, we introduce random mutations of the underlying digit. Starting from a certain digit and after some time evolution, we sample a new digit, erase all cell states that are not present in both digits and bring “alive” the cells that were not present in the original digit but are present in the new digit. This kind of mutation inherently teaches CAs to learn to process new information and adapt to changing conditions. Additionally, it exposes the cells to training states where all of the remaining cells after a perturbation are misclassifying the new digit and must recover from this catastrophic mutation. This in turn forces our CAs to learn to change their own classifications under certain circumstances.</p>

<p>We use a pixel-wise (cell-wise) cross entropy loss  on the last ten channels of each pixel, applying it after letting the CA evolve for 20 steps.</p>
<p><figure>
    <div class="vc">
    <div class="vidoverlay"></div>
    <video playsinline muted width="640px" preload="auto">
      <source src="figures/ce_runs.mp4#t=0.1" type="video/mp4">
      Your browser does not support the video tag.
    </video>
    </div>
<figcaption style="">
A first attempt at having the neural CAs classify digits. Each digit is a separate evolution of the neural CA, with the visualisations collated. Halfway through, the underlying digit is swapped for a new one - a "mutation".</figcaption>
</figure></p>

<p>The video above shows the CA classifying a batch of digits for 200 steps, which are then mutated, and we let the system evolve and classify for a further 200 more steps.</p>

<p>The results look promising overall, and we can see how our CAs are able to recover from mutations. However, keen readers may notice there is often a lack of total agreement between the cells. Often, the majority of the digit is classified correctly, but some outlier cells are still convinced they are part of a different digit, often switching back and forth in an oscillating pattern, creating a flickering effect in the visualization. However - our goal is stable, and total, agreement amongst the cells. The next experiment investigates this undesired behaviour.</p>
<h2 id='experiment-2'>Experiment 2: Solving the flickery regression</h2>
<p>Quantifying a qualitative issue is the first step to solving it. We propose the metric to track - <strong>average cell accuracy</strong>: defined as mean percentage of cells which have a correct output. We track this metric both before and after the digit is mutated.<figure style="margin-left:auto; margin-right: auto; grid-column:page; width:100%; max-width: 700px">
  <object data="figures/ce_accuracy.png" type="image/png" style="width:100%"></object>
<figcaption style="">
Average accuracy across the cells in a digit over time.</figcaption>
</figure></p>
<p>In the figure above, we show the mean percentage of correctly classified cells, across the test set, over 400 steps. At step 200, we randomly mutate the digit. Accordingly, we see a brief drop in accuracy as the cells re-organise and eventually come to agreement on what the new digit may be.</p>

<p>We immediately notice an interesting phenomenon - the cell accuracy appears to decrease over time, after the cells have come to an agreement. However - the graph does not necessarily reflect the qualitative issue of unstable labels that we set out to solve. The slow decay in accuracy may be a reflection of the lack of total agreement, but doesn’t capture the stark instability issue we see in many of the samples.</p>

<p>Instead of looking at mean agreement perhaps measuring <strong>total agreement</strong> would be more helpful. We define total agreement as the percentage of samples from the training batch where all the cells output the same label. </p>
<p><figure style="margin-left:auto; margin-right: auto; grid-column:page; width:100%; max-width:700px">
  <object data="figures/ce_agreement.png" type="image/png" style="width:100%"></object>
<figcaption style="">
Average total agreement between cells across the training samples in MNIST, over time.</figcaption>
</figure></p>

<p>This metric better captures the issues we are seeing. We see how total agreement starts at zero percent, and then spikes up to roughly 78%, only to lose more than 10% agreement over the next 100 steps. Again, there does not appear to be significantly different behaviour after mutation. Our model is clearly not only unstable in the short term, exhibiting flickering, but also it does not appear stable during longer timescales. As time goes on, cells get less sure of themselves. Let us inspect the inner states of the CA to see if we gain insight.</p>

<p><figure style="margin-left:auto; margin-right: auto; grid-column:page; width:100%; max-width:700px">
  <object data="figures/ce_magnitude.png" type="image/png" style="width:100%"></object>
<figcaption style="">
Average magnitude of the state channels in cells over cells, over time.</figcaption>
</figure></p>
<p>The figure above shows the evolution, over time, of the average magnitude of the state values of active cells (solid line), and the average magnitude of the residual updates for the active cells firing at each timestamp (dotted line). We can observe two important properties of our model: the average magnitude of each cell’s internal states looks suspiciously like it’s somewhat unbounded in its growth (at least in the time-scales in our experiments), and the average magnitude of the residual updates does not change significantly over time. We theorize a successful CA model should stabilize the magnitude of its internal states once cells find agreement.</p>

<p><strong>Change the loss to $L_2$: </strong>Using cross-entropy loss in a one-hot setting inherently always tries to increase the ratio of the incoming logit value for the correct class to the logit values of the other classes. In our case, the incoming logits exist as channels of a cell’s state. Given the recurrent nature of cell updates, we theorize the gradient may in turn be pushing all the cell state values to increase in magnitude. Furthermore, softmax cross-entropy introduces degeneracy in the the space of logits, which we theorize contributes to the lack of a shared reference range for logit values between cells. Thus, perhaps a simpler loss function would avoid these pitfalls. </p>

<p>We instead train our model with a pixel-wise $L_2$ loss with regards to one-hot vectors with the correct label arbitrarily set to $1.0$. Intuitively, a converged solution should be more stable since the raw outputs of the network are simply encouraged to stay close to the range $[0, 1]$ instead of being continually pried apart. This should both keep stable the magnitude of internal state channels and also help the cells agree on a reference range for their outputs. </p>

<p><strong>Add noise to the residual</strong>: A key idea in most schemes of regularization is to inject noise to make a classifier or model more robust.  We introduce noise sampled from a normal distribution with zero mean and 0.02 standard-deviation to the residual updates. The noise is added before the random mask of updates.</p>
<p><figure>
<div class="vc">
    <div class="vidoverlay"></div>
    <video playsinline muted width="640px" preload="auto">
      <source src="figures/l2_runs.mp4#t=0.1" type="video/mp4">
      Your browser does not support the video tag.
    </video>
</div>
<figcaption style="">
Neural CA trained with $L_2$ loss, exhibiting less instability after converging to a label.</figcaption>
</figure></p>
<p>The video above shows a batch of runs with the augmentations in place. Qualitatively, the result looks much better - less flickering and more total agreement. We now compare it to the original method using the metrics we defined.</p>
<p><figure style="margin-left:auto; margin-right: auto; grid-column:page; width:100%; max-width:700px">
  <object data="figures/ce_vs_l2_metrics.png" type="image/png" style="width:100%"></object>
<figcaption style="">
Comparison of average accuracy and total agreement 
 when using cross-entropy and when using $L_2$ loss.</figcaption>
</figure></p>

<div id=accTable style=overflow-x:scroll;grid-column:page;max-width:700px;margin-left:auto;margin-right:auto;><table class=model_table>
<thead>
<tr>
<th align="center">Model</th>
<th align="center">Top accuracy</th>
<th align="center">Accuracy @ 200 </th>
<th align="center">Top agreement</th>
<th align="center">Agreement @ 200</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center">CE</td>
<td align="center"><b>96.2 @ 80</b></td>
<td align="center"><b>95.3</b></td>
<td align="center">77.9 @ 80</td>
<td align="center">66.2</td>
</tr>
<tr>
<td align="center">$L_2$</td>
<td align="center">95.0 @ 95</td>
<td align="center">94.7</td>
<td align="center">85.5 @ 175</td>
<td align="center">85.2</td>
</tr>
<tr>
<td align="center">$L_2$ + Noise</td>
<td align="center">95.4 @ 65</td>
<td align="center"><b>95.3</b></td>
<td align="center"><b>88.2 @ 190</b></td>
<td align="center"><b>88.1</b></td>
</tr>
</tbody>
</table>
</div>


<p>The figure and table above show that cross-entropy achieves the highest accuracy of all models at roughly 80 steps. However, the accuracy at 200 steps is the same as the $L_2$ + Noise model. While accuracy and agreement degrade over time for all models, it is evident that the $L_2$ + Noise is the most stable configuration. Moreover, the total agreement after 200 steps of $L_2$ + Noise is 88%, an improvement of more than 20% as compared to the cross-entropy model. </p>
<h3>Internal states</h3>
<p>Below we compare the internal states of the augmented model versus the original.</p>
<p><figure style="margin-left:auto; margin-right: auto; grid-column:page; width:100%; max-width:700px">
  <object data="figures/magnitude_comparison.png" type="image/png" style="width:100%"></object>
<figcaption style="">
Average magnitude of state channels over time for $L_2$ loss and cross-entropy loss.</figcaption>
</figure></p>
<p>The figure above shows how switching to an $L_2$ loss successfully stabilizes the magnitude of the states, and how residual updates quickly converge to very small values after an agreement is about to be reached.</p>

<p><figure>
<div class="vc">
    <div class="vidoverlay"></div>
    <video playsinline muted preload="auto" width:100%>
      <source src="figures/l2n_horiz_states.mp4#t=0.5" type="video/mp4">
      Your browser does not support the video tag.
    </video>
</div>
<figcaption style="">
Visualisation of internal state channel values during mutations. Note the accelerated timeline after a few seconds showing the relative stability of the channel values.</figcaption>
</figure></p>
<p>Here we show the resulting dynamics of the internal states for the final model. For visualization purposes, the internal state values are squashed using arctan - as the majority of state values have a magnitude of less than one but a small number are much larger in magnitude. The states converge to stable configurations quickly and the state channels exhibit spatial continuity with the neighbouring states - i.e. we don’t see any stark discontinuities in state values between neighbouring pixels. Applying a mutation causes the CA to readapt to the new shape and form a new classification in just a few steps, after which it’s internal values are fairly stable.</p>
<h2 id='observed-robustness'>Observed robustness and limitations</h2>
<h3>Adaptation to mutation</h3>
<p>Random mutations were used during training to ensure the resulting CA was responsive to external changes. Biologically, this helps understand the insensitivity of some large-scale anatomical control mechanisms to mutations - for example, planaria continuously accumulate mutations over millennia of somatic inheritance but still regenerate the correct morphology 100% of the time in nature (and exhibit no genetic strains with new morphologies) <d-cite key="LEVIN2019125"></d-cite>. </p>
<p>This robustness to change is of critical importance for making an interactive model - in order for the cells to classify drawings “live” (an eight being completed from a six, for instance, should quickly re-classify itself as an eight). We encourage the readers to play with the interactive demo, and experience this for themselves. In this section, we want to showcase a few behaviours we found interesting.</p>

<p><figure>
    <div class="vc">
<div class="vidoverlay"></div>    
<video playsinline muted width="320px" preload="auto">
      <source src="figures/drawing_mutations.mp4#t=9.2" type="video/mp4">
      Your browser does not support the video tag.
    </video>
</div>
<figcaption style="">
Demonstration of the CA successfully re-classifying a digit when it is modified by hand.</figcaption>
</figure></p>

<p>The video above shows how the CA is able to interactively adjust to our own writing, and to change classification when the drawn digit is adjusted.</p>
<h3>Robustness to out-of-training configurations</h3>
<p>In the field of Machine Learning, it is of particular interest to see how trained models behave with out-of-band data. In the experiments sections of this article, we evaluated our model on the test set of MNIST. In this section, we go further and see how the model reacts to digits drawn by us, and not sampled from MNIST at all. We vary the shapes of the digits until the model is no longer capable of classifying them correctly. Every classification model inherently contains certain inductive biases that render them more or less robust to generalizing to out-of-band data. Our model can be seen as a recurrent convolutional model and we therefore expect it to exhibit some of the key properties of traditional convolutional models - such as translation invariance. Moreover we strongly believe the self-organising nature of this model introduces a novel inductive bias which may have interesting properties of its own. Biology offers examples of repairing to novel configurations: 2-headed planaria, once created, regenerate to this new configuration <d-cite key="OVIEDO2010188"></d-cite> which was not evolutionarily present in their “training set”. </p>
<p><figure>
<div class="vc">
    <div class="vidoverlay"></div>
    <video playsinline muted width="320px" preload="auto">
      <source src="figures/drawing_bad.mp4#t=9.0" type="video/mp4">
      Your browser does not support the video tag.
    </video>
</div>
<figcaption style="">
Demonstration of some of the failure cases of the CA.</figcaption>
</figure></p>

<p>Above, we can see our CA failing to classify properly some variants of 1 and 9. This is likely due to MNIST training data not being sufficiently representative of all writing styles. We hypothesize that more varied and extensive datasets would improve the performance. The model often converges to oscillating attractors in these situations - flipping between different classifications. This property could not arise from static classifiers such as traditional convolutional neural networks.</p>

<p><figure>
<div class="vc">
    <div class="vidoverlay"></div>
    <video playsinline muted width="320px" preload="auto">
      <source src="figures/mnist_ablation.mp4#t=16.0" type="video/mp4">
      Your browser does not support the video tag.
    </video>
</div>
<figcaption style="">
Demonstration the inherent robustness of the model to unseen sizes and variants of numbers.</figcaption>
</figure></p>
<p>Unsurprisingly, the resulting CA is translation invariant. More surprisingly - we notice the model is also scale-invariant for out-of-band scales of digits up - to a certain point. Alas, it does not generalize well enough to work for arbitrary lengths and widths.</p>
<h2 id='related-work'>Related work</h2>
<p>This article is follow-up work to Growing Neural Cellular Automata <d-cite key="mordvintsev2020growing"></d-cite>, and it is meant to be read after the latter. In this article, we purposefully skim over details of the model that were explored in the original  article, and we refer to the Growing Neural Cellular Automata article for the full model description and biological backgrounds.</p>

<p><strong>MNIST and CA</strong></p>
<p>Since CAs are easily applied to two dimensional grids, many researchers wondered if they could use them somehow to classify the MNIST dataset <d-cite key="lecun_mnist"></d-cite>. Work we aware of combines CAs with Reservoir Computing <d-cite key="alej2018reservoir, alej2020reservoir"></d-cite>, Boltzmann Machines <d-cite key="matsubara2018"></d-cite>, Evolutionary Strategies <d-cite key="oliveira2008"></d-cite>, and ensemble methods <d-cite key="WALI201877, jastrzebska2017"></d-cite>. To the best of our knowledge, we are the first to train end-to-end differentiable Neural CAs for classification purposes, and we are the first to introduce the self-classifying variant of MNIST, where each pixel in the digit needs to coordinate locally in order to come to an understanding about its label.</p>
<h2 id='discussion'>Discussion</h2>
<p>This article serves as a proof of concept for how a simple self-organising system such as CA can be used for a task such as classification if trained end-to-end through backpropagation.</p>

<p>The resulting model adapts to writing and erasing, and is surprisingly robust to certain ranges of digit stretching and brush widths. We hypothesize that self-organising models with constrained capacity may be inherently robust with good generalisation properties, and we encourage future work to test this hypothesis.</p>

<p>What our work specifically shows is that there are things we can "teach" or "train" a collective of cells to do which would be impossible for them to learn if we tried to train them by individually or if we approached this by trying to train or engineer a single cell. The cells being trained in unison (while communicating with each other) allows them to learn more complex behaviour than any attempt to train them one by one.</p>
</d-article>
<d-appendix>
<h3>Acknowledgments</h3>
<p>We thank Zhitao Gong, Sam Greydanus, Alex Groznykh, Nick Moran, Peter Whidden for their valuable conversations and feedback.</p>
<h3>Author Contributions</h3>
<p><strong>Research:</strong> Alexander came up with the Self-Organising Asynchronous Neural Cellular Automata model and Ettore contributed to its design. Alexander came up with the self-classifying MNIST digits task. Ettore designed and performed the experiments for this work. </p>

<p><strong>Demos:</strong> Ettore, Eyvind and Alexander contributed to the demo.</p>

<p><strong>Writing and Diagrams:</strong> Ettore outlined the structure of the article, created graphs and videos, and contributed to the content throughout. Eyvind contributed to the content throughout, including video making and substantive editing and writing. Michael made extensive contributions to the article text, providing the biological context for this work.</p>
<h3>Implementation details</h3>
<p><strong>TF.js playground.</strong> The demo shown in this work is made through Tensorflow.js (TF.js). In the colaboratory notebook described below, the reader can find customizable sizes of this playground, as well as more options for exploring pretrained models, trained without sampling from a pool of different initial states, or mutation mechanisms, or using a cross-entropy loss.</p>

<p><strong>Colaboratory Notebook.</strong> All of the experiments, images and videos in this article can be recreated using the single notebook referenced at the beginning of the article. Furthermore, more training configurations are easily available: training without pooling, without mutations, with a different loss, with or without residual noise. In the colab, the user can find pretrained models for all these configurations, and customizable TF.js demos where one can try any configuration.</p>
<d-footnote-list></d-footnote-list>
<d-citation-list></d-citation-list>
<d-appendix>